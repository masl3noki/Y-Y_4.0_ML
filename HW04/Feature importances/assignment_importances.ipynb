{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-512ba712fc0fc065",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "4PCY3co0zw4W"
      },
      "source": [
        "## Home assignment 08: Feature importances\n",
        "\n",
        "\n",
        "Please, fill the lines in the code below.\n",
        "Your goal is to estimate importance of the existing features using several methods.\n",
        "\n",
        "Your main goal is to estimate feature importances for Logistic Regression and Gradient Boosting using several methods.\n",
        "\n",
        "The model should be trained using only `train` part of the data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-b656a4266174b009",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "mb4RO1L9zw4Z"
      },
      "source": [
        "In this task you meet the [dataset](https://archive.ics.uci.edu/ml/datasets/Statlog+%28Vehicle+Silhouettes%29) describing different cars for multiclass ($k=4$) classification problem, but we use only binary subset for classes `bus` and `opel`. The data is available below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaW7p_JWzw4Z"
      },
      "outputs": [],
      "source": [
        "# If on colab, uncomment the following lines\n",
        "\n",
        "! wget https://raw.githubusercontent.com/girafe-ai/ml-course/23f_basic/homeworks/lab01_ml_pipeline/car_data.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-eebac6bfdf73d0bc",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "1gdgvkCtzw4a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shap\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "dataset = pd.read_csv('car_data.csv', delimiter=',', header=None).values\n",
        "data = dataset[:, :-1].astype(int)\n",
        "target = dataset[:, -1]\n",
        "binary_subset = np.array([x in ['bus', 'opel'] for x in target])\n",
        "data, target = data[binary_subset], target[binary_subset]\n",
        "\n",
        "print(data.shape, target.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdLeUSxszw4b"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "submission_dict = {}\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qB898_Ozw4b"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = data[:350, 1:], target[:350]\n",
        "X_val, y_val = data[350:, 1:], target[350:]\n",
        "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-be844269be69c387",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "Vip-US41zw4b"
      },
      "source": [
        "#### Estimating features importances using logistic regression coefficients.\n",
        "Train basic logistic regression and save its coefficients (weights)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ax5ESd-wzw4c"
      },
      "outputs": [],
      "source": [
        "lr_basic = None# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZreuN10zw4c"
      },
      "source": [
        "Check the classification results on the original train data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrYrNK1izw4c"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_train, lr_basic.predict(X_train)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4LKFxbGzw4c"
      },
      "source": [
        "And on validation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plxdRlxLzw4d"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_val, lr_basic.predict(X_val)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pszqVYx6zw4d"
      },
      "source": [
        "Find the Logistic Regression weights and save them to the variable `lr_basic_coef`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WinCQBQ1zw4d"
      },
      "outputs": [],
      "source": [
        "lr_basic_coef = None # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeE7J6Vrzw4d"
      },
      "source": [
        "It should have the same number of coefficients as number of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5zdwoHxzw4d"
      },
      "outputs": [],
      "source": [
        "assert lr_basic_coef.shape[-1] == X_train.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eOQOLLAzw4d"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "submission_dict['lr_basic_coef'] = lr_basic_coef\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uMgXrlZzw4d"
      },
      "source": [
        "#### Estimating features importances using logistic regression coefficients.\n",
        "Train basic logistic regression on scaled data and save its coefficients (weights) as well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2GWn3o0zw4d"
      },
      "outputs": [],
      "source": [
        "lr_scaled = None # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zak7dKEuzw4e"
      },
      "source": [
        "Use `StandardScaler` on your data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWX_LMXazw4e"
      },
      "outputs": [],
      "source": [
        "scaler = # YOUR CODE HERE\n",
        "X_train_scaled = # YOUR CODE HERE\n",
        "X_val_scaled = # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2y9WtB8kzw4e"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFV0tPYizw4e"
      },
      "source": [
        "Check the classification results on the scaled train data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uft5PjXzw4e"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_train, lr_scaled.predict(X_train_scaled)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF1iYGVHzw4e"
      },
      "source": [
        "And on validation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHhot7-hzw4e"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_val, lr_scaled.predict(X_val_scaled)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCvqCjdVzw4e"
      },
      "source": [
        "Save model coefficients to the variable `lr_scaled_coef`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4tu83ygzw4e"
      },
      "outputs": [],
      "source": [
        "lr_scaled_coef = None # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCL8VdIOzw4e"
      },
      "source": [
        "It should also have the same number of coefficients as number of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJA9YujLzw4f"
      },
      "outputs": [],
      "source": [
        "assert lr_scaled_coef.shape[-1] == X_train_scaled.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjZ6-zl8zw4f"
      },
      "source": [
        "Save index of the most important feature for lr_scaled to the variable `lr_scaled_most_important_index`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anKnGh6ozw4f"
      },
      "outputs": [],
      "source": [
        "lr_scaled_most_important_index = None # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsiWhfz6zw4f"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert isinstance(int(lr_scaled_most_important_index), int)\n",
        "submission_dict['lr_scaled_coef'] = lr_scaled_coef\n",
        "submission_dict['lr_scaled_most_important_index'] = lr_scaled_most_important_index\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMO4hWqWzw4f"
      },
      "source": [
        "#### Estimating features importances for logistic regression using shap\n",
        "Use [`shap` library](https://shap.readthedocs.io/en/latest/index.html) to check the importance of the features. Use [`Linear` explainer](https://shap.readthedocs.io/en/latest/generated/shap.explainers.Linear.html) and the scaled data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tz9ydLh8zw4f"
      },
      "outputs": [],
      "source": [
        "explainer = None # YOUR CODE HERE\n",
        "shap_values_scaled = explainer(X_train_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCK2-Seszw4f"
      },
      "source": [
        "Summary plot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GbE8QWnzw4f"
      },
      "outputs": [],
      "source": [
        "shap.summary_plot(shap_values_scaled, X_train_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Icn5-QFzw4f"
      },
      "source": [
        "Finally, write a function which transforms shap values to Logistic Regression coefficients. Their relations are described in the [docs](https://shap.readthedocs.io/en/latest/generated/shap.explainers.Linear.html).\n",
        "\n",
        "*Note: This task main goal is your deeper understanding of the shap importance estimation process.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHBAE6LMzw4f"
      },
      "outputs": [],
      "source": [
        "def get_coef_from_shap_values(shap_values, X_train_scaled):\n",
        "    # YOUR CODE HERE\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1pxfGWtzw4j"
      },
      "outputs": [],
      "source": [
        "coef_from_shap = get_coef_from_shap_values(shap_values_scaled, X_train_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcZsmyshzw4j"
      },
      "source": [
        "If everything is correct, the next assert should pass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49nWTUg9zw4j"
      },
      "outputs": [],
      "source": [
        "assert np.allclose(coef_from_shap, lr_scaled_coef)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkkgDOkazw4j"
      },
      "source": [
        "#### Training the GradientBoosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AQlagJ0zw4j"
      },
      "outputs": [],
      "source": [
        "gb_basic = GradientBoostingClassifier(n_estimators=10)\n",
        "gb_basic.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0CkHpMpzw4k"
      },
      "outputs": [],
      "source": [
        "gb_basic_feature_importances = None # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrHoYKlWzw4k"
      },
      "outputs": [],
      "source": [
        "gb_scaled = GradientBoostingClassifier(n_estimators=10)\n",
        "gb_scaled.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bk4Tz2dTzw4k"
      },
      "outputs": [],
      "source": [
        "gb_scaled_feature_importances = None # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XG62wMk9zw4k"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert np.allclose(gb_basic_feature_importances, gb_scaled_feature_importances, atol=1e-1)\n",
        "submission_dict['gb_basic_feature_importances'] = gb_basic_feature_importances\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNR_X9Kjzw4k"
      },
      "source": [
        "**Question:** Why are the feature importances so similar for scaled and unscaled data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUbR33j_zw4k"
      },
      "source": [
        "#### Using shap to explain trees ensemble solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7VFW80Uzw4k"
      },
      "outputs": [],
      "source": [
        "explainer = None # YOUR CODE HERE\n",
        "shap_values = explainer.shap_values(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3aaWhyVzw4k"
      },
      "outputs": [],
      "source": [
        "shap.summary_plot(shap_values, X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntBOfiZBzw4k"
      },
      "outputs": [],
      "source": [
        "gb_scaled_most_important_index = None # YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6sUFK3Fzw4l"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert isinstance(int(gb_scaled_most_important_index), int)\n",
        "submission_dict['gb_scaled_most_important_index'] = gb_scaled_most_important_index\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTbq5456zw4l"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "np.save('submission_dict_hw08.npy', submission_dict, allow_pickle=True)\n",
        "print('File saved to `submission_dict_hw.npy`')\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOSXOc9Dzw4l"
      },
      "source": [
        "Great job! Please, submit your solution to the grading system! Please, note, you need to submit both `submission_dict_hw.npy` and `get_coef_from_shap_values` function code."
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Create Assignment",
    "kernelspec": {
      "display_name": "Py3 Research",
      "language": "python",
      "name": "py3_research"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}